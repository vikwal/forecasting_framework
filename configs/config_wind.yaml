data:
  path: 'data'
  power_curves_path: '/mnt/nas/synthetic/wind/power_curves'
  nwp_path: '/mnt/nas/synthetic/multilevelfields'
  freq: '1h'
  train_frac: 1
  val_frac: 0.25 # abs from train_frac
  test_start: '2025-01-01'
  target_col: 'power'
  scale_y: False
  lag_in_col: False
  n_neighbors: 5

params:
  turbines: [
             'Enercon E-70 E4 2.300',
             #'Enercon E-82 E2 2.000',
             #'Enercon E-115 2.500',
             #'Vestas V90',
             #'Vestas V112-3.45',
             #'Vestas V80-1.8'
            ]
  known_features: [
                   #'wind_speed_t1'
                   'wind_speed_nwp',
                   'temperature_nwp',
                   'pressure_nwp',
                   'relhum_nwp',
                   'density_nwp'
                   ]
  observed_features: [
                      #'wind_speed',
                      'wind_speed_t1',
                      'power'
                      ]
  lag_known_features: [

                      ]
  aggregate_nwp_layers: 'pivot' # options: 'not', 'pivot', 'weighted_mean', 'mean'
  features_to_pivot: [
                      'wind_speed_nwp',
                      'density_nwp',
                      #'temperature_nwp',
                      #'pressure_nwp',
                      #'relhum_nwp',
                      ]
  get_density: True

model:
  output_dim: 48
  lookback: 192
  horizon: 48
  step_size: 48
  batch_size: 64
  epochs: 30
  lr: 0.0005
  optimizer: 'adam'
  loss: 'mse'
  metrics: ['mae', 'rmse', 'r^2']
  fnn:
    units: 128
    n_layers: 2
  cnn:
    filters: 64
    kernel_size: 3
    n_cnn_layers: 10
    increase_filters: False
  rnn:
    n_rnn_layers: 1
    units: 64
    dropout: 0.1
  tft:
    n_heads: 1
    hidden_dim: 45
    dropout: 0.1
  callbacks: False
  save_model: True
  shuffle: False
  create_lag: True # wether to consider observed features as lag features or not
  force_retrain: True
  parallelize: False
  verbose: 1

hpo:
  studies_path: '/mnt/nas/optuna_studies.db'
  metric: 'rmse'
  trials: 1000
  kfolds: 3
  val_split: 1
  batch_size: [32, 512]
  epochs: [1, 50]
  n_layers: [1, 4]
  n_cnn_layers: [1, 10]
  n_rnn_layers: [1, 5]
  learning_rate: [0.0001, 0.1]
  fnn:
    units: [32, 256]
  cnn:
    filters: [16, 128]
    kernel_size: [2, 5]
    increase_filters: False
  rnn:
    units: [16, 100]
    dropout: [0.0, 0.8]
  tft:
    lookback: [24, 48, 72, 96]
    n_heads: [1, 6]
    hidden_dim: [8, 128]
    dropout: [0.0, 0.8]
  fl:
    strategy: 'fedavg'
    personalize: False
    n_rounds: [1,20]
    server_lr: [0.0001, 0.1]
    beta_1: [0,1]
    beta_2: [0,1]
    tau: [0.0001, 0.1]

eval:
  results_path: 'results'
  eval_on_all_test_data: True
  retrain_interval: 0 # in hours - 0 if no retraining is wanted
  t_0: 12

fl:
  parts: []
  strategy: 'fedavg'
  n_rounds: 5
  personalize: False
  fedopt:
    server_lr: 0.001
    beta_1: 0.9
    beta_2: 0.99
    tau: 0.001
  force_retrain: True
  verbose: True
  save_history: False
  num_gpus: 1
  num_cpus: 11